{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENTP</td>\n",
       "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>INTP</td>\n",
       "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENTJ</td>\n",
       "      <td>'You're fired.|||That's another silly misconce...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              posts\n",
       "0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...\n",
       "1  ENTP  'I'm finding the lack of me in these posts ver...\n",
       "2  INTP  'Good one  _____   https://www.youtube.com/wat...\n",
       "3  INTJ  'Dear INTP,   I enjoyed our conversation the o...\n",
       "4  ENTJ  'You're fired.|||That's another silly misconce..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('mbti_1.csv')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFJ\n"
     ]
    }
   ],
   "source": [
    "MBTI = data[data.columns[0]]\n",
    "posts = data[data.columns[1]]\n",
    "\n",
    "for i in range(len(posts)):\n",
    "    posts[i] = posts[i].lower()\n",
    "    \n",
    "print(MBTI[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts_by_user = []\n",
    "for i in range(len(posts)):\n",
    "    user_post = posts[i].split('|||')\n",
    "    posts_by_user.append(user_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of posts per user\n",
    "user_post_num = [0 for i in range(len(posts_by_user))]\n",
    "for i in range(len(posts_by_user)):\n",
    "    user_post_num[i] = len(posts_by_user[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['all', 'things', 'in', 'moderation', '.', 'sims', 'is', 'indeed', 'a', 'video', 'game', ',', 'and', 'a', 'good', 'one', 'at', 'that', '.', 'note', ':', 'a', 'good', 'one', 'at', 'that', 'is', 'somewhat', 'subjective', 'in', 'that', 'i', 'am', 'not', 'completely', 'promoting', 'the', 'death', 'of', 'any', 'given', 'sim', '...']\n"
     ]
    }
   ],
   "source": [
    "# tokenize\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "posts_by_user = [[word_tokenize(y) for y in x] for x in posts_by_user]\n",
    "\n",
    "print(posts_by_user[0][13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['all', 'things', 'in', 'moderation', 'sims', 'is', 'indeed', 'a', 'video', 'game', 'and', 'a', 'good', 'one', 'at', 'that', 'note', 'a', 'good', 'one', 'at', 'that', 'is', 'somewhat', 'subjective', 'in', 'that', 'i', 'am', 'not', 'completely', 'promoting', 'the', 'death', 'of', 'any', 'given', 'sim']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "for i in range(len(posts_by_user)):\n",
    "    for j in range(len(posts_by_user[i])):\n",
    "        index = 0\n",
    "        while index < len(posts_by_user[i][j]):\n",
    "            if bool(re.search(r'[\\d]', posts_by_user[i][j][index])) or \\\n",
    "                bool(re.search('[^\\w]', posts_by_user[i][j][index])) or \\\n",
    "                bool(re.search(r'http', posts_by_user[i][j][index])):\n",
    "                posts_by_user[i][j].remove(posts_by_user[i][j][index])\n",
    "                index -= 1\n",
    "            index += 1\n",
    "            \n",
    "print(posts_by_user[0][13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['all', 'thing', 'in', 'moder', 'sim', 'is', 'inde', 'a', 'video', 'game', 'and', 'a', 'good', 'one', 'at', 'that', 'note', 'a', 'good', 'one', 'at', 'that', 'is', 'somewhat', 'subject', 'in', 'that', 'i', 'am', 'not', 'complet', 'promot', 'the', 'death', 'of', 'ani', 'given', 'sim']\n"
     ]
    }
   ],
   "source": [
    "# stem: words are reduced to their root form\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "#create an object of class Porter Stemmer\n",
    "porter = PorterStemmer()\n",
    "\n",
    "for i in range(len(posts_by_user)):\n",
    "    for j in range(len(posts_by_user[i])):\n",
    "        posts_by_user[i][j] = [porter.stem(w) for w in posts_by_user[i][j]]\n",
    "        \n",
    "print(posts_by_user[0][13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lemmatize: words in third person are changed to first person and verbs in past and future tenses are changed into present\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "for i in range(len(posts_by_user)):\n",
    "    for j in range(len(posts_by_user[i])):\n",
    "        posts_by_user[i][j] = [lemmatizer.lemmatize(w) for w in posts_by_user[i][j]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['thing', 'moder', 'sim', 'inde', 'video', 'game', 'good', 'one', 'note', 'good', 'one', 'somewhat', 'subject', 'complet', 'promot', 'death', 'ani', 'given', 'sim']\n"
     ]
    }
   ],
   "source": [
    "# remove stopwords\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "for i in range(len(posts_by_user)):\n",
    "    for j in range(len(posts_by_user[i])):\n",
    "        posts_by_user[i][j] = [w for w in posts_by_user[i][j] if not w in stop_words]\n",
    "        \n",
    "print(posts_by_user[0][13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thing moder sim inde video game good one note good one somewhat subject complet promot death ani given sim\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(posts_by_user)):\n",
    "    for j in range(len(posts_by_user[i])):\n",
    "        posts_by_user[i][j] = ' '.join(posts_by_user[i][j])\n",
    "print(posts_by_user[0][13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(posts_by_user)):\n",
    "    posts_by_user[i] = ' '.join(posts_by_user[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8675, 1986881)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "ngram_vectorizer = CountVectorizer(binary=False, ngram_range=(1, 2))\n",
    "ngram_user = ngram_vectorizer.fit_transform(posts_by_user)\n",
    "\n",
    "print(ngram_user.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1  fold\n",
      "0.7716262975778547\n",
      "0.8678200692041522\n",
      "0.556401384083045\n",
      "0.6235294117647059\n",
      "2  fold\n",
      "0.7550173010380623\n",
      "0.8581314878892734\n",
      "0.5155709342560554\n",
      "0.5965397923875433\n",
      "3  fold\n",
      "0.7750865051903114\n",
      "0.8532871972318339\n",
      "0.5446366782006921\n",
      "0.5896193771626298\n",
      "4  fold\n",
      "0.7647058823529411\n",
      "0.8823529411764706\n",
      "0.554325259515571\n",
      "0.6\n",
      "5  fold\n",
      "0.7826989619377163\n",
      "0.8505190311418686\n",
      "0.5370242214532872\n",
      "0.6145328719723183\n",
      "6  fold\n",
      "0.7681660899653979\n",
      "0.8602076124567474\n",
      "0.5377162629757786\n",
      "0.5993079584775086\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy import sparse\n",
    "from scipy import stats\n",
    "from scipy.sparse import coo_matrix, vstack\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "k = 6\n",
    "user_num = len(MBTI)\n",
    "num_validation_samples = user_num // k\n",
    "\n",
    "# first shuffle the data\n",
    "#np.random.shuffle(data)\n",
    "\n",
    "acc = [[] for i in range(4)]\n",
    "\n",
    "for fold in range(k):\n",
    "    print(fold+1, \" fold\")\n",
    "    x_val = ngram_user.tocsr()[num_validation_samples * fold : num_validation_samples * (fold + 1)][:]\n",
    "    \n",
    "    for dimension in range(4):\n",
    "        y_label = [MBTI[k][dimension] for k in range(len(MBTI))]\n",
    "        y_label = np.asarray(y_label)\n",
    "        y_label = sm.tools.categorical(y_label, drop=True)\n",
    "        y_label = y_label[:,0]\n",
    "        \n",
    "        x_train = vstack([ngram_user.tocsr()[:num_validation_samples * fold][:], ngram_user.tocsr()[num_validation_samples * (fold + 1):][:]])\n",
    "        y_train = np.array(list(y_label[:num_validation_samples * fold]) + list(y_label[num_validation_samples * (fold + 1):]))\n",
    "        y_val = np.array(y_label[num_validation_samples * fold : num_validation_samples * (fold + 1)])\n",
    "        \n",
    "        svm = SVC()\n",
    "        svm.fit(x_train, y_train)\n",
    "        y_pred = svm.predict(x_val)\n",
    "        acc_score = accuracy_score(y_val, y_pred)\n",
    "        print(acc_score)\n",
    "        acc[dimension].append(acc_score)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.76955017 0.86205306 0.54094579 0.60392157]\n"
     ]
    }
   ],
   "source": [
    "mean_acc = np.mean(np.array(acc), axis=1)\n",
    "\n",
    "print(mean_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
