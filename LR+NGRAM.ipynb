{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "stop_words = set(stopwords.words('english'))\n",
    "porter = PorterStemmer()\n",
    "\n",
    "df = pd.read_csv('mbti_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_word(word):\n",
    "    if bool(re.search(r'[\\d]', word)) or \\\n",
    "            bool(re.search('[^\\w]', word)) or \\\n",
    "            bool(re.search(r'http', word)) or \\\n",
    "            word in stop_words:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "def preprocess_post(post):\n",
    "    post = word_tokenize(post)\n",
    "    \n",
    "    post = [porter.stem(word.lower()) for word in post if filter_word(word.lower())]\n",
    "    \n",
    "    post = ' '.join(post)\n",
    "    \n",
    "    return post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ngrams(n, word_column='posts',df=pd.read_csv('mbti_1.csv')):\n",
    "    '''\n",
    "    input:\n",
    "        - df: pandas dataframe\n",
    "        - word_column: string of column name that contains the corpus in the df\n",
    "        - n: maximal length of ngrams\n",
    "    output:\n",
    "        - list of words in the bag of words\n",
    "        - the bag of words matrix for each row and word\n",
    "    '''\n",
    "    posts_by_user = [row[word_column].split('|||') for _, row in df.iterrows()]\n",
    "    corpus = [' '.join([preprocess_post(post) for post in posts]) for posts in posts_by_user]\n",
    "    \n",
    "    ngram_vectorizer = CountVectorizer(binary=False, ngram_range=(1, n), min_df=2)\n",
    "    X = ngram_vectorizer.fit_transform(corpus)\n",
    "    \n",
    "    return ngram_vectorizer.get_feature_names(), X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8675, 566706)\n"
     ]
    }
   ],
   "source": [
    "ngrams, ngram_user = get_ngrams(2)\n",
    "print(ngram_user.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold  1\n",
      "0.8463667820069204\n",
      "0.9038062283737024\n",
      "0.8491349480968858\n",
      "0.7903114186851211\n",
      "overall acc: 0.5612456747404845\n",
      "fold  2\n",
      "0.8484429065743945\n",
      "0.9010380622837371\n",
      "0.8394463667820069\n",
      "0.7896193771626298\n",
      "overall acc: 0.5647058823529412\n",
      "fold  3\n",
      "0.8505190311418686\n",
      "0.8941176470588236\n",
      "0.8491349480968858\n",
      "0.8166089965397924\n",
      "overall acc: 0.5778546712802768\n",
      "fold  4\n",
      "0.8581314878892734\n",
      "0.9072664359861592\n",
      "0.8484429065743945\n",
      "0.7958477508650519\n",
      "overall acc: 0.5674740484429066\n",
      "fold  5\n",
      "0.8519031141868512\n",
      "0.8865051903114187\n",
      "0.8422145328719723\n",
      "0.7806228373702422\n",
      "overall acc: 0.5494809688581315\n",
      "fold  6\n",
      "0.8422145328719723\n",
      "0.9100346020761245\n",
      "0.8422145328719723\n",
      "0.7681660899653979\n",
      "overall acc: 0.542560553633218\n",
      "[0.84959631 0.90046136 0.84509804 0.79019608]\n",
      "0.5605536332179931\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "from scipy.sparse import vstack\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "MBTI = df['type']\n",
    "\n",
    "def lg_kfold(feature, label, k):\n",
    "    acc = [[] for i in range(4)]\n",
    "    overall_acc = []\n",
    "    num_validation_samples = len(label) // k\n",
    "    \n",
    "    # k-fold cross validation\n",
    "    for fold in range(k):\n",
    "        print(\"fold \", fold + 1)\n",
    "        blabel = []\n",
    "        bpredict = []\n",
    "        x_val = feature.tocsr()[num_validation_samples * fold : num_validation_samples * (fold + 1)][:]\n",
    "        \n",
    "        # each dimension in MBTI\n",
    "        for dimension in range(4):\n",
    "            y = np.asarray([label[k][dimension] for k in range(len(label))])\n",
    "            y = sm.tools.categorical(y, drop=True)[:,0]\n",
    "            \n",
    "            x_train = vstack([feature.tocsr()[:num_validation_samples * fold][:], feature.tocsr()[num_validation_samples * (fold + 1):][:]])\n",
    "            y_train = np.array(list(y[:num_validation_samples * fold]) + list(y[num_validation_samples * (fold + 1):]))\n",
    "            y_val = np.array(y[num_validation_samples * fold : num_validation_samples * (fold + 1)])\n",
    "            blabel.append(y_val)\n",
    "            \n",
    "            clf = LogisticRegression(random_state=0, solver='liblinear')\n",
    "            clf.fit(x_train, y_train)\n",
    "            y_pred = clf.predict(x_val)\n",
    "            bpredict.append(y_pred)\n",
    "            \n",
    "            acc_score = accuracy_score(y_val, y_pred)\n",
    "            acc[dimension].append(acc_score)\n",
    "            print(acc_score)\n",
    "            \n",
    "        # overall accuracy\n",
    "        a = [1 if list(np.array(bpredict)[:,i]) ==  list(np.array(blabel)[:,i]) else 0 for i in range(len(y_val))]\n",
    "        overall_acc.append(sum(a)/len(a))\n",
    "        print(\"overall acc:\", sum(a)/len(a))\n",
    "        \n",
    "    mean_acc = np.mean(np.array(acc), axis=1)\n",
    "    return mean_acc, overall_acc\n",
    "        \n",
    "acc, overallacc = lg_kfold(ngram_user, MBTI, 6)\n",
    "print(acc)\n",
    "print(np.mean(np.array(overallacc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xurw1\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7716262975778547\n",
      "0.8678200692041522\n",
      "0.5570934256055363\n",
      "0.6235294117647059\n",
      "overall acc: 0.24083044982698962\n",
      "fold  2\n",
      "0.7550173010380623\n",
      "0.8581314878892734\n",
      "0.5155709342560554\n",
      "0.5965397923875433\n",
      "overall acc: 0.18685121107266436\n",
      "fold  3\n",
      "0.7750865051903114\n",
      "0.8532871972318339\n",
      "0.5453287197231834\n",
      "0.5896193771626298\n",
      "overall acc: 0.20346020761245676\n",
      "fold  4\n",
      "0.7647058823529411\n",
      "0.8823529411764706\n",
      "0.554325259515571\n",
      "0.6\n",
      "overall acc: 0.21868512110726643\n",
      "fold  5\n",
      "0.7826989619377163\n",
      "0.8505190311418686\n",
      "0.5370242214532872\n",
      "0.6145328719723183\n",
      "overall acc: 0.21730103806228374\n",
      "fold  6\n",
      "0.7681660899653979\n",
      "0.8602076124567474\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "def svm_kfold(feature, label, k):\n",
    "    acc = [[] for i in range(4)]\n",
    "    overall_acc = []\n",
    "    num_validation_samples = len(label) // k\n",
    "    \n",
    "    # k-fold cross validation\n",
    "    for fold in range(k):\n",
    "        print(\"fold \", fold + 1)\n",
    "        blabel = []\n",
    "        bpredict = []\n",
    "        x_val = feature.tocsr()[num_validation_samples * fold : num_validation_samples * (fold + 1)][:]\n",
    "        \n",
    "        # each dimension in MBTI\n",
    "        for dimension in range(4):\n",
    "            y = np.asarray([label[k][dimension] for k in range(len(label))])\n",
    "            y = sm.tools.categorical(y, drop=True)[:,0]\n",
    "            \n",
    "            x_train = vstack([feature.tocsr()[:num_validation_samples * fold][:], feature.tocsr()[num_validation_samples * (fold + 1):][:]])\n",
    "            y_train = np.array(list(y[:num_validation_samples * fold]) + list(y[num_validation_samples * (fold + 1):]))\n",
    "            y_val = np.array(y[num_validation_samples * fold : num_validation_samples * (fold + 1)])\n",
    "            blabel.append(y_val)\n",
    "            \n",
    "            svm = SVC()\n",
    "            svm.fit(x_train, y_train)\n",
    "            y_pred = svm.predict(x_val)\n",
    "            bpredict.append(y_pred)\n",
    "            \n",
    "            acc_score = accuracy_score(y_val, y_pred)\n",
    "            acc[dimension].append(acc_score)\n",
    "            print(acc_score)\n",
    "            \n",
    "        # overall accuracy\n",
    "        a = [1 if list(np.array(bpredict)[:,i]) ==  list(np.array(blabel)[:,i]) else 0 for i in range(len(y_val))]\n",
    "        overall_acc.append(sum(a)/len(a))\n",
    "        print(\"overall acc:\", sum(a)/len(a))\n",
    "        \n",
    "    mean_acc = np.mean(np.array(acc), axis=1)\n",
    "    return mean_acc, overall_acc\n",
    "        \n",
    "acc, overallacc = svm_kfold(ngram_user, MBTI, 6)\n",
    "print(acc)\n",
    "print(np.mean(np.array(overallacc)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
